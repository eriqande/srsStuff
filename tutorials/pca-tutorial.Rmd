---
title: "A quick tutorial on computing covariance matrices and PCA with srsStuff"
output: 
  html_notebook:
    toc: true
---

# Introduction

This is a hands-on practical session to get you up and running with using
the srsStuff package to do PCAs from low-coverage
whole genome sequencing data with allele read depths stored in a VCF file.

The text version of this Rmarkdown document can be found at GitHub at:
[https://github.com/eriqande/srsStuff/blob/master/tutorials/pca-tutorial.Rmd](https://github.com/eriqande/srsStuff/blob/master/tutorials/pca-tutorial.Rmd).


The srsStuff package uses
the allele depths reported in a VCF file to do single-read sampling to allow
fast and robust calculations.

There are two main pre-processing steps for doing a PCA with srsStuff:

1. First you need to prepare data from your VCF files into a flat-text
format that can be easily parsed by the C++ code engine within srsStuff.
2. Second, you must prepare the names of the individuals in your sample,
essentially obtaining a vector of the names in the order in which they appear
in your VCF file.

These topics are covered in the next section.

# Preparing data from VCF format

It is typical to have many VCF files---perhaps one for each chromosome of
a chromosomal-level assembly.  These have to all be concatenated into a single
VCF file, and then that file can be filtered however you want to, but most
importantly, it must be filtered to include **only biallelic markers**.  That
means biallelic SNPs and indels.  After that filtering, the `bcftools query` utility
is used to write out the allele depths to a simple, tab-delimited, text file for use.

I have prepared some sample data for this tutorial: two chromosomes worth
of bgzipped VCF files from 160 Chinook salmon.  This is about 126 Mb of
data that is stored in a publicly accessible folder on my CSU google drive:
[https://drive.google.com/drive/folders/1lrk7IjSyCQrvFj74Zpwcexp3pdRp5Ar4?usp=sharing](https://drive.google.com/drive/folders/1lrk7IjSyCQrvFj74Zpwcexp3pdRp5Ar4?usp=sharing)

If you want to follow along with this tutorial, _including the bcftools portions_,
you should download the four files:
```
NC_037113.1.vcf.gz
NC_037113.1.vcf.gz.csi
NC_037114.1.vcf.gz
NC_037114.1.vcf.gz.csi
```
and put them in your `~/Downloads` directory (or wherever you might want them
if you are working on a cluster...just know that you will have to account for
the directory change relative to this tutorial.) This tutorial assumes that you have
downloaded them one at a time to your `~/Downloads` directory.
Note: _leave the the VCF files gzipped_, and don't use Safari to download them,
because that tries to open them
with your address book application. 

_If you don't want to hassle with the bcftools portion_, you can just
download the files:
```
two-small-chromos-flat.txt.gz
vcf_sample_names.txt
````
If you opted to download those two files then you must decompress `two-small-chromos-flat.txt.gz` with the Unix command `gunzip two-small-chromos-flat.txt.gz`.

 

## Catenating and filtering the VCF files

This is, of course, a job for `bcftools`. Here we chain two commands together:

1. concatenate (with `bcftools concat`)
2. filter (with `bcftools view`)

And then we index the result.
```sh
cd ~/Downloads
bcftools concat NC_037113.1.vcf.gz NC_037114.1.vcf.gz | \
bcftools view -m 2 -M 2 \
    --min-af 0.01 --max-af 0.99 \
    -i 'F_MISSING < 0.5'\
    -Oz > two_small_chromos.vcf.gz
bcftools index two_small_chromos.vcf.gz
```

After that, it is useful to get an overview of how many sites and individuals
we have:
```sh
bcftools stats two_small_chromos.vcf.gz | awk '$1=="SN"' 
```
Which tells us that we have:
```
SN	0	number of samples:	160
SN	0	number of records:	310664
SN	0	number of no-ALTs:	0
SN	0	number of SNPs:	254483
SN	0	number of MNPs:	0
SN	0	number of indels:	56181
SN	0	number of others:	0
SN	0	number of multiallelic sites:	0
SN	0	number of multiallelic SNP sites:	0
```
Yay! 310,664 sites.  That should take just a couple minutes to run through.

## Extracting the sample names and the allele depths

### Samples names as they appear in the VCF

First, we need to get the sample names in the order that the appear in the VCF
file.  Once again, this is a job for `bcftools`:
```sh
# you should be in the ~/Downloads directory for this
bcftools query --list-samples two_small_chromos.vcf.gz > vcf_sample_names.txt
```
Here is what the first 10 of 160 lines of that file look like:
```
DPCh_plate1_A01_S1
DPCh_plate1_A02_S2
DPCh_plate1_A03_S3
DPCh_plate1_A04_S4
DPCh_plate1_A05_S5
DPCh_plate1_A06_S6
DPCh_plate1_A07_S7
DPCh_plate1_A08_S8
DPCh_plate1_A09_S9
DPCh_plate1_A10_S10
```
It just holds the sample names, one per line.

### Getting a flat text file of allele depths 

We also need to get the CHROM, POS and the allele depths fields
for every individual.
```sh
# you should be in the ~/Downloads directory for this
bcftools query -f '%CHROM\t%POS[\t%AD]\n' two_small_chromos.vcf.gz > two-small-chromos-flat.txt
```

# Preparing for srsStuff and the PCA calculation

## Getting the srsStuff package

First off, you must have the srsStuff package installed.  The easiest
way to do that is like this:
```r
remotes::install_github("eriqande/srsStuff", upgrade = FALSE)
```
Note that you need to have all the build tools (like XCode on a Mac) to
do this, because the package requires C++ compilation.

## Getting information about the individuals

I have included the meta data for these 160 Chinook salmon in the
srsStuff package.  We can get it like this:
```{r, message=FALSE}
library(tidyverse)
library(srsStuff)

meta_raw <- read_csv(
  system.file(
    "extdata/wgs-chinoook-samples-cleaned.csv",
    package = "srsStuff"
  )
)
```
This file has the name of each sample and the population that it belongs to.
The population names are a little cumbersome, so we shorten them up here
a little bit:
```{r}
 meta <- meta_raw %>%
  mutate(
    pop = recode(
      Population,
      "Salmon River Fall" =  "SalmR-Fall",
      "Salmon River Spring" =  "SalmR-Spri",
      "Feather River Hatchery Fall" =  "FeatH-Fall",
      "Feather River Hatchery Spring" =  "FeatH-Spri",
      "Trinity River Hatchery Fall" =  "TrinH-Fall",
      "Trinity River Hatchery Spring" =  "TrinH-Spri",
      "San Joaquin River Fall" =  "SanJo-Fall",
      "Coleman Hatchery Late Fall" =  "ColmH-LFal",
      "Sacramento River Winter" =  "SacrR-Wint",
      "Butte Creek Spring" =  "ButtC-Spri"
    )) %>%
  rename(indiv = vcf_name) %>%
  select(indiv, pop)
```
Now we have a tibble with a column `indiv` that has the sample names
in it (_as they appear in the VCF file_), and a column `pop` that says
which population each sample belongs to.  Here is what that looks like:
```{r}
meta
```
In comparison to setting up the population-specific $F_\mathrm{ST}$ calculation, there
isn't much to be done for the PCA calculation.  So, let's do it now!

# Doing the PCA calculation and extracting results

```{r}
# get the names of the samples in the order that the are in the VCF file:
snames <- read_lines("~/Downloads/vcf_sample_names.txt")

# compute the covariance matrix.  Note that if you are going to use a 
# tilde (~) in the path to the input file to denote your home directory,
# you have to wrap that in the `normalizePath()` function.  The function
# itself does not do path expansion.
CM_list <- srs_covar(
  file = normalizePath("~/Downloads/two-small-chromos-flat.txt"),
  sample_names = snames
)
```

The output above, `CM_list` is a list with the following components:

* `IBS`: a symmetrical matrix.  The $i,j-\mathrm{th}$ element is the fraction of (non-missing) sites
that were identical-by-state (had the same allele) in a single read from individual $i$ an a single read from $j$.
* `Cov`: the symmetrical covariance matrix for all pairs of individuals.
* `M`: for each pair of individuals, the number of sites at which each individual had
at least one sequenced read at the site.  This is important for interpreting outliers.
* `Mt_S`: some weird quantity that I computed for some reason at some point...
* `sample_names`: the character vector of sample names.
* `freq_thresh`: the MAF frequency threshold that was in effect (if any).  The default is 0.
* `site_counts`: named vector of the number of sites of different types.



## Processing the covariance matrix

To do a PCA and make a scatter plot of the different principal components, you need to
do an eigenvalue decomposition of the covariance matrix, and then format the results in a useful
fashion.  There is a function in srsStuff that makes it pretty easy to do this:
```{r}
P <- process_srs_covar_output(A = CM_list, npp = 4)
```

The result of the above is a list with three component:  

* `pca_pairs` is a long-format tibble in which
the top `npp` (above set to 4) PCs have been retained. This format is useful for plotting multiple
PCs against one another.
* `covars_and_num_sites` is a long-format tibble that holds the covariances between every pair of
individuals (note that each pair is listed twice---they come from a symmetrical matrix), and it also
holds the number of sites that had at least one called read from each member of the pair (in the
`num_sites` column).
* `eig` is the raw results (eigenvalues and eigenvectors) of the
decomposition of the covariance matrix.

(**Note to Me (Eric):** I should also compute the proportion of variance explained by each
PC in there, too).

Anyhoo, here are the first 100 rows of the `pca_pairs` tibble:
```{r}
P$pca_pairs %>%
  slice(1:100)
```

To make a plot of these, it might be useful to color the points by some meta data.  That meta data can be
easily joined onto the pca_pairs tibble:
```{r}
ptable <- P$pca_pairs %>%
  left_join(meta, by = c("vcf_name" = "indiv"))

# see what that looks like
head(ptable)
```

## Making a plot

Now we can make a plot with `ptable`.  It is quite easy using `ggplot2`.  Before we do it,
let's break apart the `pop` variable, splitting on the hyphen into `location` and `ecotype` which
is more descriptive.
```{r}
ptable2 <- ptable %>%
  separate(
    pop, 
    into = c("location", "ecotype"),
    sep = "-"
  )

# see what that looks like:
ptable2
```
Now we can make a nice big faceted plot. We take some pains to put different locations in different colors
```{r, fig.width=10, fig.height=8}
bp <- ggplot(
  data = ptable2, 
  mapping = aes(
    x = val_x, 
    y = val_y, 
    colour = location, 
    shape = ecotype
  )
) + 
  geom_point() +
  facet_grid(PCy ~ PCx) +
  theme_bw()

bp
```

That is actually pretty ugly.  We can do better with different point shapes and coloring the fill rather than
the whole points.  Let's define some colors and shapes:
```{r}
# and make sure that our colors or here
pca_colors <- c(
  `SalmR` =  "#bae4b3",
  `FeatH` =  "#fee5d9",
  `TrinH` =  "#238b45",
  `SanJo` =  "#fb6a4a",
  `ColmH` =  "#fcbba1",
  `SacrR` =  "#a50f15",
  `ButtC` =  "#fc9272"
)
# and set our shape values
pca_shapes <- c(
  Fall = 21,
  Spri = 24,
  LFal = 25,
  Wint = 23
)

```

```{r, fig.width=10, fig.height=8}
bp_better <- ggplot(
  data = ptable2, 
  mapping = aes(
    x = val_x, 
    y = val_y, 
    fill = location, 
    shape = ecotype
  )
) + 
  geom_point() +
  facet_grid(PCy ~ PCx) +
  theme_bw() +
  geom_point(size = 3, stroke = 0.15) +
  scale_fill_manual(values = pca_colors) +
  scale_shape_manual(values = pca_shapes) +
  theme_bw() +
  guides(
    fill = guide_legend(override.aes=list(shape=22, stroke = 0.1, size = 6)),
    shape = guide_legend(override.aes=list(stroke = 0.35, size = 4))
  )

bp_better
```
Booyah!  Note that if you want to focus just on a single pair of principal components,
you can just filter the others out in the PCx and PCy columns.  

### Coloring points by average number of sites

Sometimes individuals with low read depth drive the patterns because they don't
have a whole lot of sites shared with other individuals, so their covariances
with other individuals are poorly estimated.  It is helpful to look at the
average number of sites that each individual's covariance calculations were made
with.

We can do that like this:
```{r, fig.width=10, fig.height=8}
bp_ave_sites <- ggplot(
  data = ptable2, 
  mapping = aes(
    x = val_x, 
    y = val_y, 
    fill = ave_sites, 
    shape = ecotype
  )
) + 
  geom_point() +
  facet_grid(PCy ~ PCx) +
  theme_bw() +
  geom_point(size = 3, stroke = 0.15) +
  scale_fill_viridis_c() +
  scale_shape_manual(values = pca_shapes) +
  theme_bw() +
  guides(
    shape = guide_legend(override.aes=list(stroke = 0.35, size = 4))
  )

bp_ave_sites


```
Aha! We see that the ones that are often wonky outliers all have the lowest
average number of sites. That should give us pause.

## Plotting all pairwise covariances

It is often useful to look at all the covariances, rather than just the PCs to
diagnose problems with low read depth or poor sequencing on some individuals.  

These can be plotted from the information in the `covars_and_num_sites` component
of the output from `process_srs_covar_output()`.

Here, I am just going to give some examples of different plots that are informative.
If you are in Kristen's lab and want to talk to someone about these, give a holler
to Matt DeSaix.

### All the points, colored by num_sites
```{r}
P$covars_and_num_sites %>%
  filter(vcf_name_1 < vcf_name_2) %>%  # get each pair just once, and toss the self-comparisons
  arrange(desc(num_sites)) %>%  # make sure the ones with few sites get plotted on top
  ggplot(aes(x = covar, y = 2, colour = log10(num_sites))) +
  geom_jitter(width = 0, height = 1, alpha = 0.9) +
  scale_colour_viridis_c()
```
There are clearly some pairs that are outliers.

### Same thing, but faceted into num_sites categories

```{r}
P$covars_and_num_sites %>%
  filter(vcf_name_1 < vcf_name_2) %>%  # get each pair just once, and toss the self-comparisons
  arrange(desc(num_sites)) %>%  # make sure the ones with few sites get plotted on top
  mutate(m_group = cut(num_sites, breaks = c(0, 10, 100, 1000, 1e4, 1e5, 1e6))) %>%
  ggplot(aes(x = covar, y = 2, colour = log10(num_sites))) +
  geom_jitter(width = 0, height = 1, alpha = 0.9) +
  scale_colour_viridis_c() + 
  facet_wrap(~ m_group, ncol = 1)
 
```


### Sometimes it is worth looking at a histogram of these $160 \times 159 / 2$ values

```{r}
P$covars_and_num_sites %>%
  filter(vcf_name_1 < vcf_name_2) %>%  # get each pair just once, and toss the self-comparisons
  arrange(desc(num_sites)) %>%  # make sure the ones with few sites get plotted on top
  ggplot(aes(x = covar)) +                    
  geom_histogram(binwidth = 0.02)
```

Whoa! The outliers are so few and so far off the main cluster that you can't even
see them, even though the move the edge of the graph over so far.

